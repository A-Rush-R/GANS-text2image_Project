{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urgfiWQ29uRG",
        "outputId": "164fd2ba-12d7-4d7f-a253-bebb3f1a7424"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: visualkeras in /usr/local/lib/python3.10/dist-packages (0.0.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from visualkeras) (8.4.0)\n",
            "Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.10/dist-packages (from visualkeras) (1.22.4)\n",
            "Requirement already satisfied: aggdraw>=1.3.11 in /usr/local/lib/python3.10/dist-packages (from visualkeras) (1.3.16)\n"
          ]
        }
      ],
      "source": [
        "!pip install visualkeras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import visualkeras\n",
        "from PIL import ImageFont\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-EBYRkzcmvV"
      },
      "source": [
        "### **Do not forget to connect to GPU runtime before training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7x_d1W4m-PRp"
      },
      "outputs": [],
      "source": [
        "#importing the dataset\n",
        "(X_train,Y_train),(X_test,Y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,Y_train,Y_test=train_test_split(X_train,Y_train,test_size=0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFXXCof1Rbwf",
        "outputId": "65ad656b-978b-415a-ce9c-59b442f1c0b5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(35000, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "tFbLM_wBDWRJ"
      },
      "outputs": [],
      "source": [
        "# Normalizing the values between -1 and 1\n",
        "X_train  = X_train/255.0\n",
        "X_test = X_test/255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "f5cd4XTEBHtB"
      },
      "outputs": [],
      "source": [
        "# Create an ImageDataGenerator object with given augmentation settings(just an instance)\n",
        "\n",
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rotation_range=20,      # Random rotation within the range of [-20, 20] degrees\n",
        "    width_shift_range=0.1,  # Random horizontal shift within the range of [-0.1, 0.1] of the total width\n",
        "    height_shift_range=0.1, # Random vertical shift within the range of [-0.1, 0.1] of the total height\n",
        "    shear_range=0.2,        # Random shearing transformations within the range of [-0.2, 0.2]\n",
        "    zoom_range=0.2,         # Random zoom within the range of [0.8, 1.2]\n",
        "    horizontal_flip=True,   # Randomly flip inputs horizontally\n",
        "    fill_mode='nearest' ,    # Fill any newly created pixels with the nearest available pixel value\n",
        "    validation_split=0.2  # Split 20% of the data for validation\n",
        ")\n",
        "\n",
        "# Apply data augmentation to the training data\n",
        "augmented_images = datagen.flow(X_train, Y_train)\n",
        "\n",
        "# creating the validation data\n",
        "validation_data = datagen.flow(X_train, Y_train, subset='validation')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvBuEuh4c7V6"
      },
      "source": [
        "## **`This is an Open assignment with minimum instructions`**\n",
        "You are allowed to search all over the web--> find any articles or implement them--> try your experiments\n",
        "\n",
        "> **---> create the model**\\\n",
        "**---> tune the hyperparameters like learning_rate, filter/kernel size**\\\n",
        "**---> optimize the result**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "J9Bqkf61fGz4",
        "outputId": "3f0afe44-b32d-4faa-bbe7-5b09a242ef6f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nYou have got some experience form last assignment '\\nUse that experience this time\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "\"\"\"\n",
        "You have got some experience form last assignment '\n",
        "Use that experience this time\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "dYfJtQTAdyLh",
        "outputId": "ece10a78-d4a0-4a3a-f703-0eb9069022a8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nNow with this much freedom, you can do anything\\nSo make sure you understand what you do and after the end of this assignment\\n you will have explain all the code you tried in a viva exam\\n this will be the mid term evaluation.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "#@title **IMPORTANT ANNOUNCEMENT**\n",
        "\"\"\"\n",
        "Now with this much freedom, you can do anything\n",
        "So make sure you understand what you do and after the end of this assignment\n",
        " you will have explain all the code you tried in a viva exam\n",
        " this will be the mid term evaluation.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dJ4qpyjek7L"
      },
      "source": [
        "## **YOUR EFFORTS WILL COUNT MORE THE RESULTS YOU GET**\n",
        "> **So make sure all the time you spent on this notebook should be visible from the notebook**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "E92b0edzffZn",
        "outputId": "146ee814-f4d8-4d61-dec3-8313d8e0ff4d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nQuestion: What is Batch Normalization? Why is it used for? How does it fix the\\nproblem it is used for? [ Answer in atleast 300 words]\\n<cite your sources>\\n\\nAnswer: \\n\\nBatch normalization means adding normalization layers in betwwen the layers of our network. This solves the problem of internal covariate shift.\\n\\n\\nAn internal covariate shift occurs when there is a change in the input distribution to our network. When the input distribution changes, hidden layers \\ntry to learn to adapt to the new distribution. This slows down the training process. If a process slows down, it takes a long time to converge to a \\nglobal minimum.\\n\\nDue to this normalization “layers” between each fully connected layers, the range of input distribution of each layer stays the same, no matter the changes\\nin the previous layer. \\n\\nNormalization brings all the inputs centered around 0. This way, there is not much change in each layer input. So, layers in the network can learn from the \\nback-propagation simultaneously, without waiting for the previous layer to learn. This fastens up the training of networks.\\n\\nNetworks train faster — Each training iteration will actually be slower because of the extra calculations during the forward pass and the additional hyperparameters\\n to train during back propagation. However, it should converge much more quickly, so training should be faster overall.\\n\\n '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "\"\"\"\n",
        "Question: What is Batch Normalization? Why is it used for? How does it fix the\n",
        "problem it is used for? [ Answer in atleast 300 words]\n",
        "<cite your sources>\n",
        "\n",
        "Answer:\n",
        "\n",
        "Batch normalization means adding normalization layers in betwwen the layers of our network. This solves the problem of internal covariate shift.\n",
        "\n",
        "\n",
        "An internal covariate shift occurs when there is a change in the input distribution to our network. When the input distribution changes, hidden layers\n",
        "try to learn to adapt to the new distribution. This slows down the training process. If a process slows down, it takes a long time to converge to a\n",
        "global minimum.\n",
        "\n",
        "Due to this normalization “layers” between each fully connected layers, the range of input distribution of each layer stays the same, no matter the changes\n",
        "in the previous layer.\n",
        "\n",
        "Normalization brings all the inputs centered around 0. This way, there is not much change in each layer input. So, layers in the network can learn from the\n",
        "back-propagation simultaneously, without waiting for the previous layer to learn. This fastens up the training of networks.\n",
        "\n",
        "Networks train faster — Each training iteration will actually be slower because of the extra calculations during the forward pass and the additional hyperparameters\n",
        " to train during back propagation. However, it should converge much more quickly, so training should be faster overall.\n",
        "\n",
        "\n",
        " Resource:  Towards Data Science\n",
        "\n",
        " \"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "EQppujL4gyZZ",
        "outputId": "f4f1b3c6-7477-47f2-b8f6-0cd8f31a0a2c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nTutorial: https://www.tensorflow.org/tutorials/images/classification\\n\\nAbove tutorial does exactly the same job\\nBut I will zero marks for exact same model used in the tutorial\\n\\nYou need experiment with different layers and all those\\nexperiments should be visible by your notebooks\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "\"\"\"\n",
        "Tutorial: https://www.tensorflow.org/tutorials/images/classification\n",
        "\n",
        "Above tutorial does exactly the same job\n",
        "But I will zero marks for exact same model used in the tutorial\n",
        "\n",
        "You need experiment with different layers and all those\n",
        "experiments should be visible by your notebooks\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "R6NlKl-bB74H"
      },
      "outputs": [],
      "source": [
        "# model initialization\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "#adding first layer\n",
        "model.add(tf.keras.layers.Conv2D(32,(3,3), activation='relu',input_shape=(32,32,3)))\n",
        "\n",
        "#adding maxpooling layer\n",
        "model.add(tf.keras.layers.MaxPooling2D(2,2))\n",
        "\n",
        "# adding second layer\n",
        "model.add(tf.keras.layers.Conv2D(64, (3,3), activation ='relu'))\n",
        "\n",
        "# adding maxpooling layer\n",
        "model.add(tf.keras.layers.MaxPooling2D(2,2))\n",
        "\n",
        "#adding third layer\n",
        "model.add(tf.keras.layers.Conv2D(64, (3,3), activation ='relu'))\n",
        "\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(64, activation = 'relu'))\n",
        "\n",
        "\n",
        "# final layer\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "OnEXCG4gEv4Z"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "In the last part of the assignment\n",
        "try experimenting with learning rate.\n",
        "May be decreasing the lr might had help?\n",
        "\"\"\"\n",
        "model.compile(optimizer = tf.keras.optimizers.SGD(learning_rate=0.001),\n",
        "                  loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                  metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KiNN6SYMFBgI",
        "outputId": "cc029502-0863-442a-9d7b-f64958443290"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1094/1094 [==============================] - 31s 28ms/step - loss: 2.2808 - accuracy: 0.2875 - val_loss: 2.2662 - val_accuracy: 0.4084\n",
            "Epoch 2/10\n",
            "1094/1094 [==============================] - 29s 27ms/step - loss: 2.2389 - accuracy: 0.4325 - val_loss: 2.2064 - val_accuracy: 0.4219\n",
            "Epoch 3/10\n",
            "1094/1094 [==============================] - 29s 26ms/step - loss: 2.1540 - accuracy: 0.3117 - val_loss: 2.1067 - val_accuracy: 0.1750\n",
            "Epoch 4/10\n",
            "1094/1094 [==============================] - 33s 30ms/step - loss: 2.0725 - accuracy: 0.1803 - val_loss: 2.0529 - val_accuracy: 0.1699\n",
            "Epoch 5/10\n",
            "1094/1094 [==============================] - 33s 30ms/step - loss: 2.0349 - accuracy: 0.1450 - val_loss: 2.0238 - val_accuracy: 0.1831\n",
            "Epoch 6/10\n",
            "1094/1094 [==============================] - 29s 26ms/step - loss: 2.0142 - accuracy: 0.1426 - val_loss: 2.0067 - val_accuracy: 0.1711\n",
            "Epoch 7/10\n",
            "1094/1094 [==============================] - 28s 26ms/step - loss: 1.9951 - accuracy: 0.1360 - val_loss: 1.9892 - val_accuracy: 0.1330\n",
            "Epoch 8/10\n",
            "1094/1094 [==============================] - 30s 27ms/step - loss: 1.9785 - accuracy: 0.1345 - val_loss: 1.9721 - val_accuracy: 0.1077\n",
            "Epoch 9/10\n",
            "1094/1094 [==============================] - 32s 29ms/step - loss: 1.9613 - accuracy: 0.1316 - val_loss: 1.9440 - val_accuracy: 0.0876\n",
            "Epoch 10/10\n",
            "1094/1094 [==============================] - 30s 27ms/step - loss: 1.9386 - accuracy: 0.1265 - val_loss: 1.9268 - val_accuracy: 0.1147\n"
          ]
        }
      ],
      "source": [
        "# This is another way of dealing with the generated data\n",
        "# both X_train and Y_train are inside the augmented image\n",
        "\n",
        "history = model.fit(augmented_images, epochs=10 ,validation_data = validation_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UdIOuHAyEEUp"
      },
      "outputs": [],
      "source": [
        "#@title Visualization\n",
        "\n",
        "# just run this cell as it is\n",
        "tf.keras.utils.plot_model(model, to_file='cnn_plot.png', show_shapes=True, show_layer_names=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zllpup2ZEW1Q"
      },
      "outputs": [],
      "source": [
        "# just run this cell as it is\n",
        "visualkeras.layered_view(model, legend=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q9QQWplIFJUI"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['accuracy'],label=\"Train accuracy\")\n",
        "plt.plot(history.history['val_accuracy'], label = \"Validation accuracy\")\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6kZ4-pgwfZHn"
      },
      "outputs": [],
      "source": [
        "model.evaluate(X_test,Y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4sAtMyYeWT9"
      },
      "source": [
        "## **TRY DIFFERENT MODELS AND COMPARE THE RESULTS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HPEDcHoWeVOr"
      },
      "outputs": [],
      "source": [
        "history = model.fit(X_train, Y_train, epochs=10 ,validation_data = (X_test, Y_test))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}